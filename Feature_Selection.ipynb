{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tincorpai/tincorpai-Data-Preparation-and-Cleaning-in-Machine-Learning-/blob/master/Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f7e8e4",
      "metadata": {
        "id": "92f7e8e4"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de9c42f",
      "metadata": {
        "id": "3de9c42f"
      },
      "source": [
        "Feature selection is the process of reducing the number of input variables when developing a predictive model. It is desirable to reduce the number of input variables to both reduce the computational cost of modeling and, in many cases, to improve the performance of the model. \n",
        "\n",
        "Statistical-based feature selection methods involve evaluating the relationship between each input variable and the target variable using statistics and selecting those input variables that have the strongest relationship with the target variable. \n",
        "The choice of statistical measures depends on the data type of both the input and output variables. The following will be cover in this work:\n",
        "\n",
        "*  Feature Selection\n",
        "\n",
        "*  Statistics for Filter Feature Selection Methods\n",
        "\n",
        "*  Feature Selection With Any Data Type \n",
        "\n",
        "*  Common Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47a829c",
      "metadata": {
        "id": "e47a829c"
      },
      "source": [
        "Feature selection methods are created to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable. Some predictive modelling predictive modelling problems hae a large amount of system memory . Additionally, the performance of some models can degrade when including input variables that are not relevant to the target variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e6c9fde",
      "metadata": {
        "id": "8e6c9fde"
      },
      "source": [
        "one way to think about feature selection methods are in terms of supervised and unsupervised methods. The difference has to do with whether features are selected based on the target variable or not.\n",
        "\n",
        "*  Unsupervised Selection: Do not use the target variable (e.g. remove redundant variables)\n",
        "\n",
        "*  Supervised selection:   Use the target variable (e.g remove irrelevant variables)\n",
        "\n",
        "Example of unsupervised feature selection techniques are methods that remove redundant or dependent features using correlation or features that have few values or low variance i.e. data cleaning). Supervised feature selection techniques use the target variable, such as methods that remove irrelevant variables.\n",
        "\n",
        "\n",
        "Supervised Feature Selection methods can be classified into there groups or classes:\n",
        "\n",
        "*  Intrinsic:  Algorithms that perform automatic feature selection during training.\n",
        "\n",
        "*  Filter:  Select subsets of features based on thier relationship with the target.\n",
        "\n",
        "*  Wrapper:  Search subsets of features that perform according to a predictive model.\n",
        "\n",
        "Wrapper feature selection methods create many models with different subsets of input features and select those features that result in the best performing model according to a performance metric. This method can be computationally expensive."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f53380",
      "metadata": {
        "id": "c5f53380"
      },
      "source": [
        "The Filter selection methods make use of statistical techniques to evaluate the relationship between each input variable and the target variable, and these scores are applied as the basis to rank and choose those input variables that will be used in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "422cd3eb",
      "metadata": {
        "id": "422cd3eb"
      },
      "source": [
        "Finally, we might also have some machine learning algorithms that perform feature selection automatically as part of learning the model. This type of feature selection techniques are referred to as intrinsic feature selection methods. This includes algorithms such as penelized regression models like Lasso and decision trees, inclusing ensembles of decision trees like random forest. This type of algorithm will only include vairbles or predictors that help maximize accuracy. In these cases, the model can select best data representation.\n",
        "\n",
        "\n",
        "Feature selection is also related to dimensionality reduction techniques in that both methods seek fewer predictor variables to a predictive model. The difference is that while feature selection select to keep and remove from the dataset relevant and irrelevant features, dimensionality reduction create a projection of the data resulting in entirely new input features. As a result dimensionality reduction is an alternate to feature selection rather than a type of feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5adfa85",
      "metadata": {
        "id": "c5adfa85"
      },
      "source": [
        "## Statistics For Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6db5fb0",
      "metadata": {
        "id": "d6db5fb0"
      },
      "source": [
        "The choice of statistical measures is highly dependent upon the variable data types. The common variable data types are the numerical and categorical (such as a label). We may further subdivide numerical features into integer and floating point and categorical variables into boolean, ordinal and nominal variables. Input variables are the input variables that are supplied to the model as input. In feature selection, it is these variables that we want to reduce in size. Output variables are variables in which a model is intended to predict, this often called the response variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117cde40",
      "metadata": {
        "id": "117cde40"
      },
      "source": [
        "The statistical measures used during filter-based feature selection performed on each feature one at a time with a target variable. This mean that any interaction between input variables are not considered in the filtering process. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884d5243",
      "metadata": {
        "id": "884d5243"
      },
      "source": [
        "The type of response variable typically indicates the type of predictive modeling problem being performed. For example, a numerical output variable indicates a regression predictive modeling problem, and a categorical output variables indicates a classification predictive modeling problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b97ef9",
      "metadata": {
        "id": "44b97ef9"
      },
      "source": [
        "Most of these techniques are univariate, meaning that they evaluate each predictor in isolation. The existence of correlated predictors make it possible to select important, but redundant predictors. The obvious consequences of this issue are that too many predictors are chosen and, as a result collinearity problems arises."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b4432e",
      "metadata": {
        "id": "f3b4432e"
      },
      "source": [
        "With this framework in mind, let's review some univariate statistical measures that can be used for filter-based feature selection:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ac70901",
      "metadata": {
        "id": "0ac70901"
      },
      "source": [
        "## Numerical Input, Numerical Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de602030",
      "metadata": {
        "id": "de602030"
      },
      "source": [
        "This is a regression predictive modeling problem with numerical input variables. The most common techniques are to use a correlation coefficient, such as Pearson's for a linear correlation, or rank-based methods for a nonlinear correlation.\n",
        "\n",
        "*  Pearson's correlation Coefficient (linear).\n",
        "*  Spearman's rank coefficient (nonlinear).\n",
        "*  Mutual Information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eebb5bc",
      "metadata": {
        "id": "0eebb5bc"
      },
      "source": [
        "## Numerical Input, Categorical Output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1cc4cf5",
      "metadata": {
        "id": "c1cc4cf5"
      },
      "source": [
        "This is a classification predictive modeling problem with numerical input variables. This is the most common example of a classification problem. The common techniques are correlation based. \n",
        "\n",
        "* ANOVA correlation coefficient (linear)\n",
        "* Kendell's rank coefficient (nonlinear)\n",
        "* Mutual Information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c32451d",
      "metadata": {
        "id": "4c32451d"
      },
      "source": [
        "## Categorical Input, Numerical Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e9cc6b",
      "metadata": {
        "id": "56e9cc6b"
      },
      "source": [
        "This is a regression predictive modelling problem with categorical input variables. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be75060f",
      "metadata": {
        "id": "be75060f"
      },
      "source": [
        "## Categorical Input and Categorical Output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36260a5",
      "metadata": {
        "id": "e36260a5"
      },
      "source": [
        "This is a classification predictive modeling problem with categorical input variables.The most common correlation measure for categorical data is chi-squared test. Mutual information can also be applied as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fbd0cf5",
      "metadata": {
        "id": "1fbd0cf5"
      },
      "source": [
        "*  Chi-Squared test \n",
        "*  Mutual Information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8dcb3c8",
      "metadata": {
        "id": "a8dcb3c8"
      },
      "source": [
        "## Feature Selection With Any Data Type "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab93a92f",
      "metadata": {
        "id": "ab93a92f"
      },
      "source": [
        "One approach to handling different input variable data types is to separately select numerical input variables and categorical variable using appropriate metrics. One of such metric is called ColumnTransform class.\n",
        "\n",
        "Other methods that could be used are wrapper, stochastic global search algorithm such as genetic algorithm or simulated annealing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ff1412",
      "metadata": {
        "id": "67ff1412"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}